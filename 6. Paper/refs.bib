
@article{gannaz_estimation_nodate,
	title = {Estimation par ondelettes dans les modèles partiellement linéaires},
	language = {fr},
	author = {Gannaz, Irène},
	pages = {175},
	file = {Gannaz - Estimation par ondelettes dans les modèles partiel.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\EA8KF2GC\\Gannaz - Estimation par ondelettes dans les modèles partiel.pdf:application/pdf},
}

@article{de_miranda_estimation_2011,
	title = {Estimation of the intensity of non-homogeneous point processes via wavelets},
	volume = {63},
	issn = {0020-3157, 1572-9052},
	url = {http://link.springer.com/10.1007/s10463-010-0283-8},
	doi = {10.1007/s10463-010-0283-8},
	abstract = {In this article we consider the problem of estimating the intensity of a non-homogeneous point process on the real line. The approach used is via wavelet expansions. Estimators of the intensity are proposed and their properties are studied, including the case of thresholded versions. Properties of the estimators for non-homogeneous Poisson processes follow as special cases. An application is given for the series of daily Dow Jones indices. Extensions to more general settings are also indicated.},
	language = {en},
	number = {6},
	urldate = {2022-03-15},
	journal = {Annals of the Institute of Statistical Mathematics},
	author = {de Miranda, José Carlos Simon and Morettin, Pedro A.},
	month = dec,
	year = {2011},
	pages = {1221--1246},
	file = {de Miranda et Morettin - 2011 - Estimation of the intensity of non-homogeneous poi.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\KS898AQL\\de Miranda et Morettin - 2011 - Estimation of the intensity of non-homogeneous poi.pdf:application/pdf},
}

@article{wand_penalized_2011,
	title = {Penalized wavelets: {Embedding} wavelets into semiparametric regression},
	volume = {5},
	issn = {1935-7524},
	shorttitle = {Penalized wavelets},
	url = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-5/issue-none/Penalized-wavelets-Embedding-wavelets-into-semiparametric-regression/10.1214/11-EJS652.full},
	doi = {10.1214/11-EJS652},
	abstract = {We introduce the concept of penalized wavelets to facilitate seamless embedding of wavelets into semiparametric regression models. In particular, we show that penalized wavelets are analogous to penalized splines; the latter being the established approach to function estimation in semiparametric regression. They diﬀer only in the type of penalization that is appropriate. This fact is not borne out by the existing wavelet literature, where the regression modelling and ﬁtting issues are overshadowed by computational issues such as eﬃciency gains aﬀorded by the Discrete Wavelet Transform and partially obscured by a tendency to work in the wavelet coeﬃcient space. With penalized wavelet structure in place, we then show that ﬁtting and inference can be achieved via the same general approaches used for penalized splines: penalized least squares, maximum likelihood and best prediction within a frequentist mixed model framework, and Markov chain Monte Carlo and mean ﬁeld variational Bayes within a Bayesian framework. Penalized wavelets are also shown have a close relationship with wide data (“p ≫ n”) regression and beneﬁt from ongoing research on that topic.},
	language = {en},
	number = {none},
	urldate = {2022-03-15},
	journal = {Electronic Journal of Statistics},
	author = {Wand, M.P. and Ormerod, J.T.},
	month = jan,
	year = {2011},
	file = {Wand et Ormerod - 2011 - Penalized wavelets Embedding wavelets into semipa.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\6LTC3FIH\\Wand et Ormerod - 2011 - Penalized wavelets Embedding wavelets into semipa.pdf:application/pdf},
}

@article{gannaz_wavelet_2013,
	title = {Wavelet penalized likelihood estimation in generalized functional models},
	volume = {22},
	issn = {1133-0686, 1863-8260},
	url = {http://link.springer.com/10.1007/s11749-012-0310-6},
	doi = {10.1007/s11749-012-0310-6},
	abstract = {The paper deals with generalized functional regression. The aim is to estimate the inﬂuence of covariates on observations, drawn from an exponential distribution. The link considered has a semiparametric expression: if we are interested in a functional inﬂuence of some covariates, we authorize others to be modeled linearly. We thus consider a generalized partially linear regression model with unknown regression coefﬁcients and an unknown nonparametric function. We present a maximum penalized likelihood procedure to estimate the components of the model introducing penalty based wavelet estimators. Asymptotic rates of the estimates of both the parametric and the nonparametric part of the model are given and quasi-minimax optimality is obtained under usual conditions in literature. We establish in particular that the 1-penalty leads to an adaptive estimation with respect to the regularity of the estimated function. An algorithm based on backﬁtting and Fisher-scoring is also proposed for implementation. Simulations are used to illustrate the ﬁnite sample behavior, including a comparison with kernel- and spline-based methods.},
	language = {en},
	number = {1},
	urldate = {2022-03-15},
	journal = {TEST},
	author = {Gannaz, Irène},
	month = mar,
	year = {2013},
	pages = {122--158},
	file = {Gannaz - 2013 - Wavelet penalized likelihood estimation in general.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\NQPD48HG\\Gannaz - 2013 - Wavelet penalized likelihood estimation in general.pdf:application/pdf},
}

@article{taleb_multiresolution_2018,
	title = {Multiresolution analysis of point processes and statistical thresholding for wavelet-based intensity estimation},
	url = {http://arxiv.org/abs/1803.11202},
	abstract = {We take a wavelet based approach to the analysis of point processes and the estimation of the ﬁrst order intensity under a continuous time setting. A multiresolution analysis of a point process is formulated which motivates the deﬁnition of homogeneity at diﬀerent scales of resolution, termed J-th level homogeneity. Further to this, the activity in a point processes’ ﬁrst order behavior at diﬀerent scales of resolution is also deﬁned and termed L-th level innovation. Likelihood ratio tests for both these properties are proposed with asymptotic distributions provided, even when only a single realization of the point process is observed. The test for L-th level innovation forms the basis for a collection of statistical strategies for thresholding coeﬃcients in a wavelet based estimator of the intensity function. These thresholding strategies are shown to outperform the existing local hard thresholding strategy on a range of simulation scenarios.},
	language = {en},
	urldate = {2022-03-15},
	journal = {arXiv:1803.11202 [math, stat]},
	author = {Taleb, Youssef and Cohen, Edward A. K.},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.11202},
	keywords = {Mathematics - Statistics Theory, Statistics - Methodology},
	annote = {Comment: 48 pages, 8 figures},
	file = {Taleb et Cohen - 2018 - Multiresolution analysis of point processes and st.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\TZA6MWKK\\Taleb et Cohen - 2018 - Multiresolution analysis of point processes and st.pdf:application/pdf},
}

@article{luo_additive_2020,
	title = {Additive {Poisson} {Process}: {Learning} {Intensity} of {Higher}-{Order} {Interaction} in {Stochastic} {Processes}},
	shorttitle = {Additive {Poisson} {Process}},
	url = {http://arxiv.org/abs/2006.08982},
	abstract = {We present the Additive Poisson Process (APP), a novel framework that can model the higher-order interaction effects of the intensity functions in stochastic processes using lower dimensional projections. Our model combines the techniques in information geometry to model higher-order interactions on a statistical manifold and in generalized additive models to use lower-dimensional projections to overcome the effects from the curse of dimensionality. Our approach solves a convex optimization problem by minimizing the KL divergence from a sample distribution in lower dimensional projections to the distribution modeled by an intensity function in the stochastic process. Our empirical results show that our model is able to use samples observed in the lower dimensional space to estimate the higher-order intensity function with extremely sparse observations.},
	language = {en},
	urldate = {2022-03-15},
	journal = {arXiv:2006.08982 [cs, stat]},
	author = {Luo, Simon and Zhou, Feng and Azizi, Lamiae and Sugiyama, Mahito},
	month = jun,
	year = {2020},
	note = {arXiv: 2006.08982},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 14 pages, 8 figures, pre-print},
	file = {Luo et al. - 2020 - Additive Poisson Process Learning Intensity of Hi.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\IYD2FK8Z\\Luo et al. - 2020 - Additive Poisson Process Learning Intensity of Hi.pdf:application/pdf},
}

@article{reynaud-bouret_near_2010,
	title = {Near optimal thresholding estimation of a {Poisson} intensity on the real line},
	volume = {4},
	issn = {1935-7524},
	url = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-4/issue-none/Near-optimal-thresholding-estimation-of-a-Poisson-intensity-on-the/10.1214/08-EJS319.full},
	doi = {10.1214/08-EJS319},
	language = {en},
	number = {none},
	urldate = {2022-03-15},
	journal = {Electronic Journal of Statistics},
	author = {Reynaud-Bouret, Patricia and Rivoirard, Vincent},
	month = jan,
	year = {2010},
	file = {Reynaud-Bouret et Rivoirard - 2010 - Near optimal thresholding estimation of a Poisson .pdf:C\:\\Users\\yvenn\\Zotero\\storage\\C5R5IDEB\\Reynaud-Bouret et Rivoirard - 2010 - Near optimal thresholding estimation of a Poisson .pdf:application/pdf},
}

@article{reynaud-bouret_spike_nodate,
	title = {Spike trains as (in)homogeneous {Poisson} processes or {Hawkes} processes: non-parametric adaptive estimation and goodness-of-fit tests},
	abstract = {This article aims to propose new non-parametric adaptive estimation methods and to adapt other recent similar results to the setting of spike trains analysis. After brieﬂy recalling main features of the homogeneous Poisson model, we focus on two main generalizations of this process : the inhomogeneous Poisson model, which is non-stationary, and the Hawkes model, which can take into account interactions. Goodness-of-ﬁt tests are also proposed and are proved to be of prescribed asymptotical level. They enable us to test these non-parametric models. Various simulations show good performance of the estimation and test procedures. A complete analysis is also performed with these tools on single unit activity recorded on a monkey during a sensory-motor task. We can show that the homogeneous Poisson process hypothesis is always rejected and that the inhomogeneous Poisson process hypothesis is rarely accepted. The Hawkes model seems to ﬁt most of the data.},
	language = {en},
	author = {Reynaud-Bouret, Patricia and Tuleau-Malot, Christine and Rivoirard, Vincent and Grammont, Franck},
	pages = {74},
	file = {Reynaud-Bouret et al. - Spike trains as (in)homogeneous Poisson processes .pdf:C\:\\Users\\yvenn\\Zotero\\storage\\HRUHUF5C\\Reynaud-Bouret et al. - Spike trains as (in)homogeneous Poisson processes .pdf:application/pdf},
}

@article{lambert_reconstructing_2018,
	title = {Reconstructing the functional connectivity of multiple spike trains using {Hawkes} models},
	volume = {297},
	issn = {01650270},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165027017304442},
	doi = {10.1016/j.jneumeth.2017.12.026},
	abstract = {Background: Statistical models that predict neuron spike occurrence from the earlier spiking activity of the whole recorded network are promising tools to reconstruct functional connectivity graphs. Some of the previously used methods are in the general statistical framework of the multivariate Hawkes processes. However, they usually require a huge amount of data, some prior knowledge about the recorded network, and/or may produce an increasing number of spikes along time during simulation. New Method: Here, we present a method, based on least-square estimators and LASSO penalty criteria, for a particular class of Hawkes processes that can be used for simulation.
Results: Testing our method on small networks modeled with Leaky Integrate and Fire demonstrated that it eﬃciently detects both excitatory and inhibitory connections. The few errors that occasionally occur with complex networks including common inputs, weak and chained connections, can be discarded based on objective criteria.
Comparison with existing methods: With respect to other existing methods, the present one allows to reconstruct functional connectivity of small networks without prior knowledge of their properties or architecture, using an experimentally realistic amount of data.
Conclusions: The present method is robust, stable, and can be used on a personal computer as a routine procedure to infer connectivity graphs and generate simulation models from simultaneous spike train recordings.},
	language = {en},
	urldate = {2022-03-15},
	journal = {Journal of Neuroscience Methods},
	author = {Lambert, Régis C. and Tuleau-Malot, Christine and Bessaih, Thomas and Rivoirard, Vincent and Bouret, Yann and Leresche, Nathalie and Reynaud-Bouret, Patricia},
	month = mar,
	year = {2018},
	pages = {9--21},
	file = {Lambert et al. - 2018 - Reconstructing the functional connectivity of mult.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\EQFWK6QT\\Lambert et al. - 2018 - Reconstructing the functional connectivity of mult.pdf:application/pdf},
}

@article{antoniadis_penalized_2011,
	title = {Penalized likelihood regression for generalized linear models with non-quadratic penalties},
	volume = {63},
	issn = {0020-3157, 1572-9052},
	url = {http://link.springer.com/10.1007/s10463-009-0242-4},
	doi = {10.1007/s10463-009-0242-4},
	abstract = {One popular method for ﬁtting a regression function is regularization: minimize an objective function which enforces a roughness penalty in addition to coherence with the data. This is the case when formulating penalized likelihood regression for exponential families. Most smoothing methods employ quadratic penalties, leading to linear estimates, and are in general incapable of recovering discontinuities or other important attributes in the regression function. In contrast, nonlinear estimates are generally more accurate. In this paper, we focus on nonparametric penalized likelihood regression methods using splines and a variety of nonquadratic penalties, pointing out common basic principles. We present an asymptotic analysis of convergence rates that justiﬁes the approach. We report on a simulation study including comparisons between our method and some existing ones. We illustrate our approach with an application to Poisson nonparametric regression modeling of frequency counts of reported AIDS (Acquired Immune Deﬁciency Syndrome) cases in the United Kingdom.},
	language = {en},
	number = {3},
	urldate = {2022-03-15},
	journal = {Annals of the Institute of Statistical Mathematics},
	author = {Antoniadis, Anestis and Gijbels, Irène and Nikolova, Mila},
	month = jun,
	year = {2011},
	pages = {585--615},
	file = {Antoniadis et al. - 2011 - Penalized likelihood regression for generalized li.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\AHSDI4RP\\Antoniadis et al. - 2011 - Penalized likelihood regression for generalized li.pdf:application/pdf},
}

@article{amato_forecasting_2021,
	title = {Forecasting high resolution electricity demand data with additive models including smooth and jagged components},
	volume = {37},
	issn = {01692070},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169207020300583},
	doi = {10.1016/j.ijforecast.2020.04.001},
	abstract = {Short-Term Load Forecasting (STLF) is a fundamental instrument in the efficient operational management and planning of electric utilities. Emerging smart grid technologies pose new challenges and opportunities. Although load forecasting at the aggregate level has been extensively studied, electrical load forecasting at fine-grained geographical scales of households is more challenging. Among existing approaches, semi-parametric generalized additive models (GAM) have been increasingly popular due to their accuracy, flexibility, and interpretability. Their applicability is justified when forecasting is addressed at higher levels of aggregation, since the aggregated load pattern contains relatively smooth additive components. High resolution data are highly volatile, forecasting the average load using GAM models with smooth components does not provide meaningful information about the future demand. Instead, we need to incorporate irregular and volatile effects to enhance the forecast accuracy. We focus on the analysis of such hybrid additive models applied on smart meters data and show that it leads to improvement of the forecasting performances of classical additive models at low aggregation levels.},
	language = {en},
	number = {1},
	urldate = {2022-03-15},
	journal = {International Journal of Forecasting},
	author = {Amato, Umberto and Antoniadis, Anestis and De Feis, Italia and Goude, Yannig and Lagache, Audrey},
	month = jan,
	year = {2021},
	pages = {171--185},
	file = {Amato et al. - 2021 - Forecasting high resolution electricity demand dat.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\P2QJWXGD\\Amato et al. - 2021 - Forecasting high resolution electricity demand dat.pdf:application/pdf},
}

@article{amato_estimation_2017,
	title = {Estimation and group variable selection for additive partial linear models with wavelets and splines},
	volume = {51},
	abstract = {In this paper we study sparse high dimensional additive partial linear models with nonparametric additive components of heterogeneous smoothness. We review several existing algorithms that have been developed for this problem in the recent literature, highlighting the connections between them, and present some computationally efﬁcient algorithms for ﬁtting such models. To achieve optimal rates in large sample situations we use hybrid P-splines and block wavelet penalisation techniques combined with adaptive (group) LASSO-like procedures for selecting the additive components in the nonparametric part of the models. Hence, the component selection and estimation in the nonparametric part may be viewed as a functional version of estimation and grouped variable selection. This allows to take advantage of several oracle results which yield asymptotic optimality of estimators in high-dimensional but sparse additive models. Numerical implementations of our procedures for proximal like algorithms are discussed. Large sample properties of the estimates and of the model selection are presented and the results are illustrated with simulated examples and a real data analysis.},
	language = {en},
	number = {2},
	journal = {South African Statistical Journal},
	author = {Amato, Umberto and Antoniadis, Anestis},
	month = dec,
	year = {2017},
	pages = {37},
	file = {Amato et Antoniadis - ESTIMATION AND GROUP VARIABLE SELECTION FOR ADDITI.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\LV8R93SQ\\Amato et Antoniadis - ESTIMATION AND GROUP VARIABLE SELECTION FOR ADDITI.pdf:application/pdf},
}

@inproceedings{brillinger_wavelet_1997,
	address = {Pacific Grove, CA, USA},
	title = {Some wavelet analyses of point process data},
	volume = {2},
	isbn = {978-0-8186-8316-9},
	url = {http://ieeexplore.ieee.org/document/679073/},
	doi = {10.1109/ACSSC.1997.679073},
	language = {en},
	urldate = {2022-03-15},
	booktitle = {Conference {Record} of the {Thirty}-{First} {Asilomar} {Conference} on {Signals}, {Systems} and {Computers} ({Cat}. {No}.{97CB36136})},
	publisher = {IEEE Comput. Soc},
	author = {Brillinger, D.R.},
	year = {1997},
	pages = {1087--1091},
	file = {Brillinger - 1997 - Some wavelet analyses of point process data.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\AEGMT635\\Brillinger - 1997 - Some wavelet analyses of point process data.pdf:application/pdf},
}

@techreport{leblanc_maximum_2006,
	type = {Technical {Report}},
	title = {Maximum {Likelihood} {Estimation} in {Poisson} {Regression} via {Wavelet} {Model} {Selection} {Running} title : {Poisson} regression via model selection},
	url = {https://sites.uclouvain.be/IAP-Stat-Phase-V-VI/PhaseV/publications_2006/TR/TR0607.pdf},
	abstract = {In this work we estimate the regression function for Poisson variables, for a deterministic design in [0, 1]. Our ﬁnal estimator, which is adaptive to the data, is selected among a collection of maximum likelihood estimators with respect to a penalized empirical Kullback-Leibler risk. We obtain an oracle inequality over the Kullback-Leibler risk for any ﬁxed size n of the design. Moreover, we state an asymptotic lower bound for this risk over Sobolev spaces and prove that our estimator reaches this rate. Hence, the selected estimator is asymptotically minimax over these spaces. We also present numerical experiments, including a strategy to adjust the constants involved in the penalty function.},
	language = {en},
	number = {0607},
	author = {Leblanc, Frederique and Letue, Frederique},
	year = {2006},
	pages = {32},
	file = {Leblanc et Letue - Maximum Likelihood Estimation in Poisson Regressio.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\8LFBECUE\\Leblanc et Letue - Maximum Likelihood Estimation in Poisson Regressio.pdf:application/pdf},
}

@article{youngman_generalised_2017,
	title = {Generalised additive point process models for natural hazard occurrence: {Generalised} additive point process models},
	volume = {28},
	issn = {11804009},
	shorttitle = {Generalised additive point process models for natural hazard occurrence},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/env.2444},
	doi = {10.1002/env.2444},
	language = {en},
	number = {4},
	urldate = {2022-05-16},
	journal = {Environmetrics},
	author = {Youngman, Benjamin D. and Economou, Theodoros},
	month = jun,
	year = {2017},
	pages = {e2444},
	file = {Youngman et Economou - 2017 - Generalised additive point process models for natu.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\N6ZSKJVS\\Youngman et Economou - 2017 - Generalised additive point process models for natu.pdf:application/pdf},
}

@article{cebrian_nhpoisson_2015,
	title = {\textbf{{NHPoisson}} : {An} \textit{{R}} {Package} for {Fitting} and {Validating} {Nonhomogeneous} {Poisson} {Processes}},
	volume = {64},
	issn = {1548-7660},
	shorttitle = {\textbf{{NHPoisson}}},
	url = {http://www.jstatsoft.org/v64/i06/},
	doi = {10.18637/jss.v064.i06},
	abstract = {NHPoisson is an R package for the modeling of nonhomogeneous Poisson processes in one dimension. It includes functions for data preparation, maximum likelihood estimation, covariate selection and inference based on asymptotic distributions and simulation methods. It also provides speciﬁc methods for the estimation of Poisson processes resulting from a peak over threshold approach. In addition, the package supports a wide range of model validation tools and functions for generating nonhomogenous Poisson process trajectories. This paper is a description of the package and aims to help those interested in modeling data using nonhomogeneous Poisson processes.},
	language = {en},
	number = {6},
	urldate = {2022-05-16},
	journal = {Journal of Statistical Software},
	author = {Cebrián, Ana C. and Abaurrea, Jesús and Asín, Jesús},
	year = {2015},
	file = {Cebrián et al. - 2015 - NHPoisson  An R Package for Fitting.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\WAWE5SE8\\Cebrián et al. - 2015 - NHPoisson  An R Package for Fitting.pdf:application/pdf},
}

@article{achcar_climate_2022,
	title = {Climate {Change}: {Use} of {Non}-{Homogeneous} {Poisson} {Processes} for {Climate} {Data} in {Presence} of a {Change}-{Point}},
	volume = {27},
	issn = {1420-2026, 1573-2967},
	shorttitle = {Climate {Change}},
	url = {https://link.springer.com/10.1007/s10666-021-09797-z},
	doi = {10.1007/s10666-021-09797-z},
	abstract = {In this study, non-homogeneous Poisson processes (NHPP) are used to analyze climate data. The data were collected over a certain period time and consist of the yearly average precipitation, yearly average temperature and yearly average maximum temperature for some regions of the world. Different existing parametric forms depending on time and on unknown parameters are assumed for the intensity/rate function (t), t ≥ 0 of the NHPP. In the present context, the Poisson events of interest are the numbers of years that a climate variable measurement has exceeded a given threshold of interest. The threshold corresponds to the overall average measurements of each climate variable taking into account here. Two versions of the NHPP model are considered in the study, one version without including change points and one version including a change point. The parameters included in the model are estimated under a Bayesian approach using standard Markov chain Monte Carlo (MCMC) methods such as the Gibbs sampling and Metropolis–Hastings algorithms. The models are applied to climate data from Kazakhstan and Uzbekistan, in Central Asia and from the USA obtained over several years.},
	language = {en},
	number = {2},
	urldate = {2022-05-16},
	journal = {Environmental Modeling \& Assessment},
	author = {Achcar, Jorge Alberto and de Oliveira, Ricardo Puziol},
	month = apr,
	year = {2022},
	pages = {385--398},
	file = {Achcar et de Oliveira - 2022 - Climate Change Use of Non-Homogeneous Poisson Pro.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\V4VGD6WP\\Achcar et de Oliveira - 2022 - Climate Change Use of Non-Homogeneous Poisson Pro.pdf:application/pdf},
}

@book{streit_poisson_2010,
	address = {Boston, MA},
	title = {Poisson {Point} {Processes}},
	isbn = {978-1-4419-6922-4 978-1-4419-6923-1},
	url = {http://link.springer.com/10.1007/978-1-4419-6923-1},
	language = {en},
	urldate = {2022-05-16},
	publisher = {Springer US},
	author = {Streit, Roy L.},
	year = {2010},
	doi = {10.1007/978-1-4419-6923-1},
}

@inproceedings{zhang_advanced_2015,
	address = {Denver, CO, USA},
	title = {An advanced data driven model for residential electric vehicle charging demand},
	isbn = {978-1-4673-8040-9},
	url = {http://ieeexplore.ieee.org/document/7286396/},
	doi = {10.1109/PESGM.2015.7286396},
	abstract = {As the electric vehicle (EV) is becoming a significant component of the loads, an accurate and valid model for the EV charging demand is the key to enable accurate load forecasting, demand respond, system planning, and several other important applications. We propose a data driven queuing model for residential EV charging demand by performing big data analytics on smart meter measurements. The data driven model captures the non-homogeneity and periodicity of the residential EV charging behavior through a self-service queue with a periodic and non-homogeneous Poisson arrival rate, an empirical distribution for charging duration and a finite calling population. Upon parameter estimation, we further validate the model by comparing the simulated data series with real measurements. The hypothesis test shows the proposed model accurately captures the charging behavior. We further acquire the long-run average steady state probabilities and simultaneous rate of the EV charging demand through simulation output analysis.},
	language = {en},
	urldate = {2022-05-16},
	booktitle = {2015 {IEEE} {Power} \& {Energy} {Society} {General} {Meeting}},
	publisher = {IEEE},
	author = {Zhang, Xiaochen and Grijalva, Santiago},
	month = jul,
	year = {2015},
	pages = {1--5},
	file = {Zhang et Grijalva - 2015 - An advanced data driven model for residential elec.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\P73GEDRH\\Zhang et Grijalva - 2015 - An advanced data driven model for residential elec.pdf:application/pdf},
}

@article{ngailo_non_2016,
	title = {Non {Homogeneous} {Poisson} {Process} {Modelling} of {Seasonal} {Extreme} {Rainfall} {Events} in {Tanzania}},
	volume = {5},
	abstract = {Extreme rainfall events due to heavy rainfall can vary greatly. This variability can be explained by different factors such as season of the year, temperature and local topography, among others. Statistical models using Extreme Value Theory have been used to model extreme weather events which assume stationarity of rainfall process. However, the stationarity requirement is not met in reality for rainfall data because rainfall time series usually exhibit seasonality. A stochastic model based on a non- homogeneous Poisson Process (NHPP) charactezised by a time-dependent intensity of rainfall occurrence, is employed in to study the seasonal and trend effects on extreme events modelling of daily rainfalls exceeding prefixed threshold value. Dataset from 14 Tanzania rainfall stations over the period 1981–2014 was used. The Akaike information criterion and likelihood ratio test methods were used to select NHPP model that best fits the data. The results showed a good fit for time–varying intensity of rainfall occurrence process by the first order harmonic Fourier law and improved analysis as well as modelling of extreme rainfall using NHPP intensity function.},
	language = {en},
	number = {10},
	journal = {International Journal of Science and Research},
	author = {Ngailo, Triphonia and Shaban, Nyimvua and Reuder, Joachim and Rutalebwa, Edwin and Mugume, Isaac},
	year = {2016},
	pages = {12},
	file = {Ngailo et al. - 2013 - Non Homogeneous Poisson Process Modelling of Seaso.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\86RASYIR\\Ngailo et al. - 2013 - Non Homogeneous Poisson Process Modelling of Seaso.pdf:application/pdf},
}

@article{aktas_estimation_2009,
	title = {Estimation of change point and compound {Poisson} process parameters for the earthquake data in {Turkey}},
	volume = {20},
	issn = {11804009, 1099095X},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/env.937},
	doi = {10.1002/env.937},
	abstract = {The existence of change point in the Turkish earthquake data is investigated. For this purpose, the 218 earthquake data of magnitude 5 and higher, between the north (39.00–42.008) and the east (26.00–45.008) coordinates in Turkey from 12 July 1900 to 28 February 2007 are used. The characteristic function of the magnitude is derived. Poisson distribution is used to describe the recurrence times. In addition, using the compound Poisson process, the expected value and variance are estimated and computed for the loss of life and damaged buildings after the change point. Copyright \# 2008 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {4},
	urldate = {2022-05-16},
	journal = {Environmetrics},
	author = {Aktas, Serpîl and Konsuk, Hande and Yîḡîter, Ayten},
	month = jun,
	year = {2009},
	pages = {416--427},
	file = {Aktas et al. - 2009 - Estimation of change point and compound Poisson pr.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\56NDJNHI\\Aktas et al. - 2009 - Estimation of change point and compound Poisson pr.pdf:application/pdf},
}

@article{hansen_lasso_2015,
	title = {Lasso and probabilistic inequalities for multivariate point processes},
	volume = {21},
	issn = {1350-7265},
	url = {https://projecteuclid.org/journals/bernoulli/volume-21/issue-1/Lasso-and-probabilistic-inequalities-for-multivariate-point-processes/10.3150/13-BEJ562.full},
	doi = {10.3150/13-BEJ562},
	language = {en},
	number = {1},
	urldate = {2022-05-16},
	journal = {Bernoulli},
	author = {Hansen, Niels Richard and Reynaud-Bouret, Patricia and Rivoirard, Vincent},
	month = feb,
	year = {2015},
	file = {Hansen et al. - 2015 - Lasso and probabilistic inequalities for multivari.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\L39DIDB8\\Hansen et al. - 2015 - Lasso and probabilistic inequalities for multivari.pdf:application/pdf},
}

@article{donoho_ideal_1994,
	title = {Ideal spatial adaptation by wavelet shrinkage},
	volume = {81},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article/81/3/425/256924},
	doi = {10.1093/biomet/81.3.425},
	language = {en},
	number = {3},
	urldate = {2022-05-16},
	journal = {Biometrika},
	author = {Donoho, David L and Johnstone, Iain M},
	month = sep,
	year = {1994},
	pages = {425--455},
	file = {Version soumise:C\:\\Users\\yvenn\\Zotero\\storage\\CWUAPMFV\\Donoho et Johnstone - 1994 - Ideal spatial adaptation by wavelet shrinkage.pdf:application/pdf},
}

@book{daley_introduction_2003,
	address = {New York},
	series = {Probability and its {Applications}},
	title = {An {Introduction} to the {Theory} of {Point} {Processes}},
	isbn = {978-0-387-95541-4},
	url = {http://link.springer.com/10.1007/b97277},
	language = {en},
	urldate = {2022-05-16},
	publisher = {Springer-Verlag},
	author = {Daley, D. J. and Vere-Jones, D.},
	year = {2003},
	doi = {10.1007/b97277},
}

@book{wood_generalized_2017,
	edition = {2},
	title = {Generalized {Additive} {Models}: {An} {Introduction} with {R}},
	isbn = {978-1-315-37027-9},
	shorttitle = {Generalized {Additive} {Models}},
	url = {https://www.taylorfrancis.com/books/9781498728348},
	language = {en},
	urldate = {2022-05-16},
	publisher = {Chapman and Hall/CRC},
	author = {Wood, Simon N.},
	month = may,
	year = {2017},
	doi = {10.1201/9781315370279},
}

@article{bigot_intensity_2013,
	title = {Intensity estimation of non-homogeneous {Poisson} processes from shifted trajectories},
	volume = {7},
	issn = {1935-7524},
	url = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-7/issue-none/Intensity-estimation-of-non-homogeneous-Poisson-processes-from-shifted-trajectories/10.1214/13-EJS794.full},
	doi = {10.1214/13-EJS794},
	number = {none},
	urldate = {2022-05-17},
	journal = {Electronic Journal of Statistics},
	author = {Bigot, Jérémie and Gadat, Sébastien and Klein, Thierry and Marteau, Clément},
	month = jan,
	year = {2013},
	file = {Texte intégral:C\:\\Users\\yvenn\\Zotero\\storage\\6ZXXP3JQ\\Bigot et al. - 2013 - Intensity estimation of non-homogeneous Poisson pr.pdf:application/pdf},
}

@article{dabo-niang_probability_2008,
	title = {Probability {Density} {Functions} of the {Empirical} {Wavelet} {Coefficients} of {Multidimensional} {Poisson} {Intensities}},
	volume = {22},
	doi = {10.1007/978-3-7908-2062-1_35},
	language = {en},
	number = {2},
	urldate = {2022-05-17},
	journal = {Brazilian Journal of Probability and Statistics},
	author = {de Miranda, José Carlos Simon},
	collaborator = {Dabo-Niang, Sophie and Ferraty, Frédéric},
	month = dec,
	year = {2008},
	pages = {157--164},
}

@book{hardle_partially_2000,
	title = {Partially {Linear} {Models}},
	url = {https://mpra.ub.uni-muenchen.de/39562/},
	language = {en},
	author = {Hardle, Wolfgang and Liang, Hua and Gao, Jiti},
	month = sep,
	year = {2000},
	file = {Hardle et al. - PARTIALLY LINEAR MODELS.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\AZ2AVR7L\\Hardle et al. - PARTIALLY LINEAR MODELS.pdf:application/pdf},
}

@article{friedman_projection_1981,
	title = {Projection {Pursuit} {Regression}},
	volume = {76},
	url = {https://www.jstor.org/stable/2287576},
	language = {en},
	number = {376},
	journal = {Journal of the American Statistical Association},
	author = {Friedman, Jerome H and Stuetzle, Werner},
	month = dec,
	year = {1981},
	pages = {817--823},
	file = {Friedman et Stuetzle - 2022 - Projection Pursuit Regression.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\SEMIYNLH\\Friedman et Stuetzle - 2022 - Projection Pursuit Regression.pdf:application/pdf},
}

@article{hastie_generalized_1986,
	title = {Generalized {Additive} {Models}},
	volume = {1},
	url = {https://www.jstor.org/stable/2245459},
	abstract = {Likelihood-based regression models such as the normal linear regression model and the linear logistic model, assume a linear (or some other parametric) form for the covariates X1, X2, *--, Xp. We introduce the class of generalized additive models which replaces the linear form E fjXj by a sum of smooth functions E sj(Xj). The sj(.)'s are unspecified functions that are estimated using a scatterplot smoother, in an iterative procedure we call the local scoring algorithm. The technique is applicable to any likelihood-based regression model: the class of generalized linear models contains many of these. In this class the linear predictor q = E fjXj is replaced by the additive predictor E sj(Xj); hence, the name generalized additive models. We illustrate the technique with binary response and survival data. In both cases, the method proves to be useful in uncovering nonlinear covariate effects. It has the advantage of being completely automatic, i.e., no "detective work" is needed on the part of the statistician. As a theoretical underpinning, the technique is viewed as an empirical method of maximizing the expected log likelihood, or equivalently, of minimizing the Kullback-Leibler distance to the true model.},
	language = {en},
	number = {3},
	journal = {Statistical Science},
	author = {Hastie, Trevor and Tibshirani, Robert},
	year = {1986},
	pages = {297--318},
	file = {Hastie et Tibshirani - 2022 - Generalized Additive Models.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\8GG99I6T\\Hastie et Tibshirani - 2022 - Generalized Additive Models.pdf:application/pdf},
}

@article{buja_linear_1989,
	title = {Linear {Smoothers} and {Additive} {Models}},
	volume = {17},
	issn = {0090-5364},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-17/issue-2/Linear-Smoothers-and-Additive-Models/10.1214/aos/1176347115.full},
	doi = {10.1214/aos/1176347115},
	language = {en},
	number = {2},
	urldate = {2022-05-18},
	journal = {The Annals of Statistics},
	author = {Buja, Andreas and Hastie, Trevor and Tibshirani, Robert},
	month = jun,
	year = {1989},
	file = {Buja et al. - 1989 - Linear Smoothers and Additive Models.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\85M4ILP3\\Buja et al. - 1989 - Linear Smoothers and Additive Models.pdf:application/pdf},
}

@article{gu_minimizing_1991,
	title = {Minimizing {GCV}/{GML} {Scores} with {Multiple} {Smoothing} {Parameters} via the {Newton} {Method}},
	volume = {12},
	issn = {0196-5204, 2168-3417},
	url = {http://epubs.siam.org/doi/10.1137/0912021},
	doi = {10.1137/0912021},
	abstract = {The (modified) Newton method is adapted to optimize generalized cross validation (GCV) and generalized maximum likelihood (GML) scores with multiple smoothing parameters. The main concerns in solving the optimization problem are the speed and the reliability of the algorithm, as well as the invariance of the algorithm under transformations under which the problem itself is invariant. The proposed algorithm is believed to be highly efficient for the problem, though it is still rather expensive for large data sets, since its operational counts are (2/3)kn + O(n2), with k the number of smoothing parameters and n the number of observations. Sensible procedures for computing good starting values are also proposed, which should help in keeping the execution load to the minimum possible. The algorithm is implemented in Rkpack [RKPACK and its applications: Fitting smoothing spline models, Tech. Report 857, Department of Statistics, University of Wisconsin, Madison, WI, 1989] and illustrated by examples of fitting additive and interaction spline models. It is noted that the algorithm can also be applied to the maximum likelihood (ML) and the restricted maximum likelihood (REML) estimation of the variance component models.},
	language = {en},
	number = {2},
	urldate = {2022-05-18},
	journal = {SIAM Journal on Scientific and Statistical Computing},
	author = {Gu, Chong and Wahba, Grace},
	month = mar,
	year = {1991},
	pages = {383--398},
	file = {Gu et Wahba - 1991 - Minimizing GCVGML Scores with Multiple Smoothing .pdf:C\:\\Users\\yvenn\\Zotero\\storage\\JRSD23UE\\Gu et Wahba - 1991 - Minimizing GCVGML Scores with Multiple Smoothing .pdf:application/pdf},
}

@article{wood_modelling_2000,
	title = {Modelling and smoothing parameter estimation with multiple quadratic penalties},
	volume = {62},
	issn = {1369-7412, 1467-9868},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/1467-9868.00240},
	doi = {10.1111/1467-9868.00240},
	abstract = {Penalized likelihood methods provide a range of practical modelling tools, including spline smoothing, generalized additive models and variants of ridge regression. Selecting the correct weights for penalties is a critical part of using these methods and in the single-penalty case th analyst has several well-founded techniques to choose from. However, many modelling problem suggest a formulation employing multiple penalties, and here general methodology is lacking. A wid family of models with multiple penalties can be fitted to data by iterative solution of the generalize ridge regression problem minimize IIW1/2(Xp - y)112p + pm1 ,p'Sip (p is a parameter vector, X design matrix, Si a non-negative definite coefficient matrix defining the ith penalty with assoc ated smoothing parameter 0i, W a diagonal weight matrix, y a vector of data or pseudodata and an 'overall' smoothing parameter included for computational efficiency). This paper shows how smoothing parameter selection can be performed efficiently by applying generalized cross-validation to this problem and how this allows non-linear, generalized linear and linear models to be fitted using multiple penalties, substantially increasing the scope of penalized modelling methods. Examples o non-linear modelling, generalized additive modelling and anisotropic smoothing are given.},
	language = {en},
	number = {2},
	urldate = {2022-05-18},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Wood, S. N.},
	month = may,
	year = {2000},
	pages = {413--428},
	file = {Wood - 2000 - Modelling and smoothing parameter estimation with .pdf:C\:\\Users\\yvenn\\Zotero\\storage\\XQ6HSKGN\\Wood - 2000 - Modelling and smoothing parameter estimation with .pdf:application/pdf},
}

@article{craven_smoothing_1979,
	title = {Smoothing noisy data with spline functions},
	volume = {31},
	abstract = {Smoothing splines are well known to provide nice curves which smooth discrete, noisy data. We obtain a practical, effective method for estimating the optimum amount of smoothing from the data. Derivatives can be estimated from the data by differentiating the resulting (nearly) optimally smoothed spline.},
	language = {en},
	journal = {Numerische Mathematik},
	author = {Craven, Peter and Wahba, Grace},
	year = {1979},
	pages = {377--403},
	file = {Craven et Wahba - Smoothing noisy data with spline functions.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\R5MUGK5N\\Craven et Wahba - Smoothing noisy data with spline functions.pdf:application/pdf},
}

@article{antoniadis_regularization_2001,
	title = {Regularization of {Wavelet} {Approximations}},
	volume = {96},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1198/016214501753208942},
	doi = {10.1198/016214501753208942},
	language = {en},
	number = {455},
	urldate = {2022-05-18},
	journal = {Journal of the American Statistical Association},
	author = {Antoniadis, Anestis and Fan, Jianqing},
	month = sep,
	year = {2001},
	pages = {939--967},
	file = {Antoniadis et Fan - 2001 - Regularization of Wavelet Approximations.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\VLGU7TP3\\Antoniadis et Fan - 2001 - Regularization of Wavelet Approximations.pdf:application/pdf},
}

@article{chang_wavelet_2004,
	title = {Wavelet estimation of partially linear models},
	volume = {47},
	issn = {01679473},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167947303002445},
	doi = {10.1016/j.csda.2003.10.018},
	abstract = {A wavelet approach is presented for estimating a partially linear model (PLM). We ÿnd an estimator of the PLM by minimizing the square of the l2 norm of the residual vector while penalizing the l1 norm of the wavelet coe cients of the nonparametric component. This approach, an extension of the wavelet approach for nonparametric regression problems, avoids the restrictive smoothness requirements for the nonparametric function of the traditional smoothing approaches for PLM, such as smoothing spline, kernel and piecewise polynomial methods. To solve the optimization problem, an e cient descent algorithm with an exact line search is presented. Simulation results are given to demonstrate e ectiveness of our method.},
	language = {en},
	number = {1},
	urldate = {2022-05-18},
	journal = {Computational Statistics \& Data Analysis},
	author = {Chang, Xiao-Wen and Qu, Leming},
	month = aug,
	year = {2004},
	pages = {31--48},
	file = {Chang et Qu - 2004 - Wavelet estimation of partially linear models.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\3A83PRZU\\Chang et Qu - 2004 - Wavelet estimation of partially linear models.pdf:application/pdf},
}

@article{meyer_wavelet-based_2003,
	title = {Wavelet-based estimation of a semiparametric generalized linear model of {fMRI} time-series},
	volume = {22},
	issn = {0278-0062},
	url = {http://ieeexplore.ieee.org/document/1199633/},
	doi = {10.1109/TMI.2003.809587},
	abstract = {This paper addresses the problem of detecting significant changes in fMRI time series that are correlated to a stimulus time course. This paper provides a new approach to estimate the parameters of a semiparametric generalized linear model of fMRI time series. The fMRI signal is described as the sum of two effects: a smooth trend and the response to the stimulus. The trend belongs to a subspace spanned by large scale wavelets. The wavelet transform provides an approximation to the Karhunen–Loève transform for the long memory noise and we have developed a scale space regression that permits to carry out the regression in the wavelet domain while omitting the scales that are contaminated by the trend. In order to demonstrate that our approach outperforms the state-of-the art detrending technique, we evaluated our method against a smoothing spline approach. Experiments with simulated data and experimental fMRI data, demonstrate that our approach can infer and remove drifts that cannot be adequately represented with splines.},
	language = {en},
	number = {3},
	urldate = {2022-05-18},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Meyer, F.G.},
	month = mar,
	year = {2003},
	pages = {315--322},
	file = {Meyer - 2003 - Wavelet-based estimation of a semiparametric gener.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\SNEFIXVP\\Meyer - 2003 - Wavelet-based estimation of a semiparametric gener.pdf:application/pdf},
}

@article{fadili_penalized_2005,
	title = {Penalized partially linear models using sparse representations with an application to {fMRI} time series},
	volume = {53},
	issn = {1053-587X},
	url = {http://ieeexplore.ieee.org/document/1495881/},
	doi = {10.1109/TSP.2005.853207},
	abstract = {In this paper, we consider modeling the nonparametric component in partially linear models (PLMs) using linear sparse representations, e.g., wavelet expansions. Two types of representations are investigated, namely, orthogonal bases (complete) and redundant overcomplete expansions. For bases, we introduce a regularized estimator of the nonparametric part. The important contribution here is that the nonparametric part can be parsimoniously estimated by choosing an appropriate penalty function for which the hard and soft thresholding estimators are special cases. This allows us to represent in an effective manner a broad class of signals, including stationary and/or nonstationary signals and avoids excessive bias in estimating the parametric component. We also give a fast estimation algorithm. The method is then generalized to handle the case of overcomplete representations. A large-scale simulation study is conducted to illustrate the ﬁnite sample properties of the estimator. The estimator is ﬁnally applied to real neurophysiological functional magnetic resonance imaging (MRI) data sets that are suspected to contain both smooth and transient drift features.},
	language = {en},
	number = {9},
	urldate = {2022-05-18},
	journal = {IEEE Transactions on Signal Processing},
	author = {Fadili, J.M. and Bullmore, E.},
	month = sep,
	year = {2005},
	pages = {3436--3448},
	file = {Fadili et Bullmore - 2005 - Penalized partially linear models using sparse rep.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\HPTSIP8R\\Fadili et Bullmore - 2005 - Penalized partially linear models using sparse rep.pdf:application/pdf},
}

@article{liu_statistical_2017,
	title = {Statistical inference for generalized additive partially linear models},
	volume = {162},
	issn = {0047259X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0047259X17304517},
	doi = {10.1016/j.jmva.2017.07.011},
	abstract = {The class of Generalized Additive Models (GAMs) is a powerful tool which has been well studied. It helps to identify additive regression structure that can be determined even more sharply via test procedures when some component functions have a parametric form. Generalized Additive Partially Linear Models (GAPLMs) enjoy the simplicity of GLMs and the flexibility of GAMs because they combine both parametric and nonparametric components. We use the hybrid spline-backfitted kernel estimation method, which combines the best features of both spline and kernel methods, to make fast, efficient and reliable estimation under an α-mixing condition. In addition, simultaneous confidence corridors (SCCs) for testing overall trends and empirical likelihood confidence regions for parameters are provided under an independence condition. The asymptotic properties are obtained and simulation results support the theoretical properties. As an illustration, we use GAPLM methodology to improve the accuracy ratio of the default predictions for 19,610 German companies. The quantlet for this paper are available on https://github.com.},
	language = {en},
	urldate = {2022-05-18},
	journal = {Journal of Multivariate Analysis},
	author = {Liu, Rong and Härdle, Wolfgang K. and Zhang, Guoyi},
	month = nov,
	year = {2017},
	pages = {1--15},
	file = {Liu et al. - 2017 - Statistical inference for generalized additive par.pdf:C\:\\Users\\yvenn\\Zotero\\storage\\5NSXXDSF\\Liu et al. - 2017 - Statistical inference for generalized additive par.pdf:application/pdf},
}
